{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements.tx\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cuda version\n",
    "\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Configure Pytorch to use 'cudaMallocAsync' as the allocator\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'backend:cudaMallocAsync'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"Get the best available device for PyTorch.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "\n",
    "        # The flag below controls whether to allow TF32 on matmul.\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        # The flag below controls whether to allow TF32 on cuDNN.\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "        # Print GPU info\n",
    "        print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "        # Set up GPU memory management\n",
    "        memory_limit_mb = 4095.5  # Adjust as needed\n",
    "\n",
    "        # Fetching total memory of GPU\n",
    "        total_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "        print(f\"Total GPU memory: {total_memory / 1024**2:.2f} MB\")\n",
    "\n",
    "        # Setting memory limit\n",
    "        memory_limit = memory_limit_mb * 1024 ** 2\n",
    "        memory_fraction = memory_limit / total_memory\n",
    "        torch.cuda.set_per_process_memory_fraction(memory_fraction, device=0)\n",
    "\n",
    "        print(f\"Set GPU memory fraction to {memory_fraction:.2%}\")\n",
    "\n",
    "        # Empty cache to measure memory usage\n",
    "        torch.cuda.empty_cache()\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "        print(\"Using Apple Silicon MPS device\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        print(\"Using CPU device\")\n",
    "\n",
    "    return torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU optimization\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# Set device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_memory = True if device.type == 'cuda' else False\n",
    "pin_memory_device = 'cuda' if device.type == 'cuda' else ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load & transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape constants, width, height, and number of channels\n",
    "IMG_WIDTH = 384\n",
    "IMG_HEIGHT = 216\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform without normalization\n",
    "initial_transforms = v2.Compose([\n",
    "    v2.Resize((IMG_WIDTH, IMG_HEIGHT)),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary dataset to calculate mean and std\n",
    "temp_dataset = ImageFolder(root='../data/merged_pool', transform=initial_transforms)\n",
    "\n",
    "temp_loader = DataLoader(temp_dataset, batch_size=64, shuffle=False, num_workers=6, pin_memory=pin_memory, pin_memory_device=pin_memory_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calc_stats = True\n",
    "\n",
    "if calc_stats:\n",
    "    print(f\"Computing dataset statistics using device: {device}\")\n",
    "    print(f\"Number of images to process: {len(temp_dataset)}\")\n",
    "\n",
    "    # Initialize tensors to accumulate the sum and squared sum of channels\n",
    "    channels_sum = torch.zeros(3, device=device)\n",
    "    channels_sqrd_sum = torch.zeros(3, device=device)\n",
    "    num_batches = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterating over the data loader with a progress bar\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(temp_loader, desc=\"Computing mean/std\")):\n",
    "        # Move data to the specified device\n",
    "        data = data.to(device, non_blocking=True)\n",
    "\n",
    "        # Used mixed precision for faster computation\n",
    "        with autocast(device.type):\n",
    "            # Calculating and adding the mean and squared mean of each channel\n",
    "            channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "            channels_sqrd_sum += torch.mean(data ** 2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            batch_time = time.time() - start_time\n",
    "            print(f\"\\nProcessed {batch_idx * temp_loader.batch_size} images in {batch_time:.2f}s\")\n",
    "\n",
    "    # Calculate overall mean and standard deviation\n",
    "    mean = channels_sum / num_batches\n",
    "    std = torch.sqrt((channels_sqrd_sum / num_batches) - (mean ** 2))\n",
    "\n",
    "    mean = mean.cpu().tolist()\n",
    "    std = std.cpu().tolist()\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTotal processing time: {total_time:.2f} seconds\")\n",
    "    print(f\"Dataset mean: {mean}\")\n",
    "    print(f\"Dataset std: {std}\")\n",
    "\n",
    "    # Release memory\n",
    "    del temp_dataset, temp_loader, channels_sum, channels_sqrd_sum, data\n",
    "    gc.collect()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    mean=[0.5479778051376343, 0.526210367679596, 0.4944702088832855]\n",
    "    std=[0.2237844169139862, 0.23763211071491241, 0.26044926047325134]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Define transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform and data augmentation for training dataset\n",
    "train_transforms = v2.Compose([\n",
    "    v2.Resize((384, 216)),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    v2.RandomRotation(degrees=10),\n",
    "    v2.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    v2.RandomPerspective(distortion_scale=0.3, p=0.3),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform for validation dataset\n",
    "val_transforms = v2.Compose([\n",
    "    v2.Resize((384, 216)),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=mean, std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Partition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and validation datasets with appropriate transforms\n",
    "train_data = ImageFolder(root='../data/merged_pool', transform=train_transforms)\n",
    "\n",
    "val_data = ImageFolder(root='../data/validation_pool', transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for training and validation datasets\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=6, pin_memory=pin_memory, pin_memory_device=pin_memory_device)\n",
    "\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False, num_workers=6, pin_memory=pin_memory, pin_memory_device=pin_memory_device)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Building the convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnoSymbolClassifier(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # First convolutional block\n",
    "        self.conv1_block = nn.Sequential(\n",
    "            # 1x1 convolution to reduce channel dimensions\n",
    "            nn.Conv2d(3, 8, 1, 1), \n",
    "            # Batch normalization for stability           \n",
    "            nn.BatchNorm2d(8),               \n",
    "            nn.ReLU(),\n",
    "            # Padding to maintain spatial dimensions                        \n",
    "            nn.ReflectionPad2d(1), \n",
    "            # 3x3 convolution to capture more spatial features           \n",
    "            nn.Conv2d(8, 16, 3, 1),           \n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 1, 1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            # Max pooling to reduce spatial dimensions\n",
    "            nn.MaxPool2d(2, 2),               \n",
    "        )\n",
    "\n",
    "        # Second convolutional block\n",
    "        self.conv2_block = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 1, 1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(16, 32, 3, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 1, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.conv3_block = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, 1, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # Fourth convolutional block\n",
    "        self.conv4_block = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(64, 128, 3, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # Flatten layer to convert 2D feature maps to 1D feature vectors\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128 * (IMG_HEIGHT // 16) * (IMG_WIDTH // 16), 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            # Dropout for regularization\n",
    "            nn.Dropout(0.2)  \n",
    "        )\n",
    "\n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # Third fully connected layer\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # Output layer\n",
    "        self.fc4 = nn.Linear(64, 54)  # 54 classes for classification\n",
    "\n",
    "    def forward(self, x) -> torch.utils.data.Dataset:\n",
    "        x = self.conv1_block(x)  \n",
    "        x = self.conv2_block(x)  \n",
    "        x = self.conv3_block(x)  \n",
    "        x = self.conv4_block(x)  \n",
    "        x = self.flatten(x)      \n",
    "        x = self.fc1(x)          \n",
    "        x = self.fc2(x)          \n",
    "        x = self.fc3(x)         \n",
    "        x = self.fc4(x)          \n",
    "\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "model = UnoSymbolClassifier()\n",
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(64, IMG_CHANNELS, IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the specified device and compile it for faster performance\n",
    "model.to(device, non_blocking=True)\n",
    "model = torch.compile(model, backend=\"inductor\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Optimising model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Learning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the learning rate and weight decay for the optimizer and number of epochs\n",
    "LEARNING_RATE = 6e-4\n",
    "WEIGHT_DECAY = 1e-6\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Optimizer & cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Adam optimizer for training the model, with weight decay for regularization\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer scheduler to reduce learning rate on plateauing of validation loss\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.25, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    # Initialize gradient scaler for mixed precision\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Total number of samples in the dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    training_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(device.type):\n",
    "            # Forward pass to calculate predictions\n",
    "            pred = model(X)\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        scaler.scale(loss).backward()\n",
    "        # Update model parameters\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        training_loss += loss.item() * X.size(0)\n",
    "        \n",
    "        # Count correct predictions\n",
    "        correct += (pred.argmax(1) == y).type(torch.float32).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss_item = loss.item()\n",
    "            current = batch * len(X)\n",
    "            print(f\"loss: {loss_item:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    avg_loss = training_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Define validate & test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Disable gradient computation for evaluation to reduce memory usage and speed up computations\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)  # Move data to device\n",
    "\n",
    "            with autocast(device.type):\n",
    "                pred = model(X)\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "            test_loss += loss.item() * X.size(0)\n",
    "            correct += (pred.argmax(1) == y).type(torch.float32).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    avg_loss = test_loss / total\n",
    "    accuracy = correct / total\n",
    "    print(f\"Avg loss: {avg_loss:>8f}, Accuracy: {(100*accuracy):>0.1f}%\\n\")\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Define overfitting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overfitting(train_loss, val_loss, train_acc, val_acc, threshold=0.1):\n",
    "    # Calculate the absolute difference between training and validation loss/accuracy\n",
    "    loss_gap = abs(train_loss - val_loss)\n",
    "    acc_gap = abs(train_acc - val_acc)\n",
    "\n",
    "    # Determine if overfitting is occurring based on the defined threshold\n",
    "    is_overfitting = (loss_gap > threshold) and (train_acc > val_acc + threshold)\n",
    "\n",
    "    if is_overfitting:\n",
    "        print(f\"Warning: Possible overfitting detected\")\n",
    "        print(f\"Loss gap: {loss_gap:.4f}, Accuracy gap: {acc_gap:.4f}\")\n",
    "\n",
    "    return is_overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "epoch_times = []\n",
    "\n",
    "best_model_metrics = None\n",
    "stopped_early = False\n",
    "is_overfitting = 0\n",
    "patience = 300\n",
    "total_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    # Execute the training loop and retrieve training loss and accuracy\n",
    "    train_loss, train_accuracy = train_loop(train_loader, model, loss_fn, optimizer)\n",
    "\n",
    "    scheduler.step(train_loss)\n",
    "\n",
    "    # Execute the validation loop and retrieve validation loss and accuracy\n",
    "    val_loss, val_accuracy = test_loop(val_loader, model, loss_fn)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    epoch_times.append(epoch_time)\n",
    "\n",
    "    # Append training and validation metrics to their respective lists\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} completed in {epoch_time:.2f} seconds\")\n",
    "    print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\\n\")\n",
    "\n",
    "    # Increment overfitting counter if overfitting detected\n",
    "    if check_overfitting(train_loss, val_loss, train_accuracy, val_accuracy):\n",
    "        is_overfitting += 1\n",
    "    else:\n",
    "        is_overfitting = 0\n",
    "\n",
    "    #  Check all conditions\n",
    "    accuracy_gap = abs(train_accuracy - val_accuracy)\n",
    "    conditions_met = (\n",
    "        train_loss >= 0.1 and\n",
    "        val_loss >= 0.1 and\n",
    "        train_accuracy <= 0.975 and\n",
    "        val_accuracy <= 0.975 and\n",
    "        accuracy_gap <= 0.07\n",
    "    )\n",
    "\n",
    "    # Save model if conditions are met and validation loss improved\n",
    "    if train_loss >= 0.1 and train_accuracy <= 0.975:\n",
    "        best_model_metrics = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'val_accuracy': val_accuracy\n",
    "        }\n",
    "        torch.save(model.state_dict(), '../data/models/best_symbol_classifier.pth')\n",
    "\n",
    "    # Stop if overfitting persists for multiple epochs\n",
    "    if is_overfitting >= patience:\n",
    "        print(f\"Early stopping triggered due to persistent overfitting.\")\n",
    "        stopped_early = True\n",
    "        break\n",
    "\n",
    "total_training_time = time.time() - total_start_time\n",
    "\n",
    "# Save both models\n",
    "torch.save(model.state_dict(), '../data/models/full_symbol_classifier.pth')\n",
    "\n",
    "if best_model_metrics:\n",
    "    print(\"\\nBest model saved with metrics:\")\n",
    "    for key, value in best_model_metrics.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nTraining complete in {total_training_time:.2f} seconds\")\n",
    "print(\"\\n-------------------------------\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Plot model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(1, len(train_losses) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses for validation and training datasets\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_losses, label='Training Loss')\n",
    "plt.plot(epochs_range, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Accuracy graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracies for validation and training datasets\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. Epoch duration graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time taken per epoch\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, epoch_times, label='Time per Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Time Taken per Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
