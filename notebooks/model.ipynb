{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"Get the best available device for PyTorch.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "\n",
    "        # The flag below controls whether to allow TF32 on matmul.\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        # The flag below controls whether to allow TF32 on cuDNN.\n",
    "        torch.backends.cudnn.allow_tf16 = True\n",
    "\n",
    "        # Print GPU info\n",
    "        print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "        \n",
    "        # Set up GPU memory management\n",
    "        memory_limit_mb = 4095.5  # Adjust as needed\n",
    "\n",
    "        total_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "\n",
    "        memory_limit = memory_limit_mb * 1024 ** 2\n",
    "        memory_fraction = memory_limit / total_memory\n",
    "\n",
    "        torch.cuda.set_per_process_memory_fraction(memory_fraction, device=0)\n",
    "\n",
    "        print(f\"Set GPU memory fraction to {memory_fraction:.2%}\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "        print(\"Using Apple Silicon MPS device\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        print(\"Using CPU device\")\n",
    "    \n",
    "    return torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_memory = True if device.type == 'cuda' else False\n",
    "pin_memory_device = 'cuda' if device.type == 'cuda' else ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load & transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create transforms without normalization to calculate dataset statistics\n",
    "initial_transforms = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float16, scale=True)\n",
    "])\n",
    "\n",
    "label_transforms = v2.Lambda(\n",
    "    lambda y: torch.zeros(54, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y, dtype=torch.long), value=1)\n",
    ")\n",
    "\n",
    "# Create temporary dataset to calculate mean and std\n",
    "temp_dataset = ImageFolder(root='../data/new_pool', transform=initial_transforms, target_transform=label_transforms)\n",
    "\n",
    "temp_loader = DataLoader(temp_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=pin_memory, pin_memory_device=pin_memory_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_stats = True\n",
    "\n",
    "if calc_stats:\n",
    "    print(f\"Computing dataset statistics using device: {device}\")\n",
    "    print(f\"Number of images to process: {len(temp_dataset)}\")\n",
    "\n",
    "    channels_sum = torch.zeros(3, device=device)\n",
    "    channels_sqrd_sum = torch.zeros(3, device=device)\n",
    "    num_batches = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(temp_loader, desc=\"Computing mean/std\")):\n",
    "        data = data.to(device)  # Add non_blocking=True\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_sqrd_sum += torch.mean(data ** 2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            batch_time = time.time() - start_time\n",
    "            print(f\"\\nProcessed {batch_idx * temp_loader.batch_size} images in {batch_time:.2f}s\")\n",
    "\n",
    "    mean = channels_sum / num_batches\n",
    "    std = torch.sqrt(channels_sqrd_sum / num_batches - mean ** 2)\n",
    "\n",
    "    mean = mean.cpu().tolist()\n",
    "    std = std.cpu().tolist()\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTotal processing time: {total_time:.2f} seconds\")\n",
    "    print(f\"Dataset mean: {mean}\")\n",
    "    print(f\"Dataset std: {std}\")\n",
    "else:\n",
    "    mean=[0.36145609617233276, 0.3521592915058136, 0.3483520746231079]\n",
    "    std=[0.20100851356983185, 0.21270669996738434, 0.254261314868927]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Define transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.RandomHorizontalFlip(p=0.2),\n",
    "    v2.RandomVerticalFlip(p=0.2),\n",
    "    # New subtle augmentations\n",
    "    v2.ColorJitter(\n",
    "        brightness=0.1,  # Subtle brightness changes for different lighting\n",
    "        contrast=0.1,    # Subtle contrast changes for different cameras/lighting\n",
    "        saturation=0.1,  # Subtle color saturation changes\n",
    "    ),\n",
    "    v2.RandomAdjustSharpness(sharpness_factor=1.1, p=1.0),  # Subtle sharpness changes\n",
    "    # Small perspective changes to simulate different card angles\n",
    "    v2.RandomPerspective(\n",
    "        distortion_scale=0.15,  # Keep perspective changes minimal\n",
    "        p=0.2                   # Apply only 30% of the time\n",
    "    ),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.RandomAdjustSharpness(sharpness_factor=1.1, p=1.0),  # Subtle sharpness changes\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=mean, std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Partition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with appropriate transforms\n",
    "full_dataset = ImageFolder(root='../data/new_pool/', transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split ratios\n",
    "train_ratio = 0.70\n",
    "val_ratio = 0.20\n",
    "test_ratio = 0.10\n",
    "\n",
    "# calculate lengths\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(train_ratio * total_size)\n",
    "val_size = int(val_ratio * total_size)\n",
    "test_size = total_size - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val/test datasets with appropriate transforms\n",
    "train_data, val_data, test_data = random_split(\n",
    "    full_dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
    ")\n",
    "\n",
    "# Override transforms for validation and test sets\n",
    "train_data.dataset.transform = train_transforms\n",
    "val_data.dataset.transform = val_transforms\n",
    "test_data.dataset.transform = val_transforms\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4, pin_memory=pin_memory, pin_memory_device=pin_memory_device)\n",
    "\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False, num_workers=4, pin_memory=pin_memory, pin_memory_device=pin_memory_device)  \n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4, pin_memory=pin_memory, pin_memory_device=pin_memory_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Building the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape constants\n",
    "IMG_WIDTH = 360\n",
    "IMG_HEIGHT = 640\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Defining the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1_block = nn.Sequential(\n",
    "            nn.Conv2d(IMG_CHANNELS, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv2_block = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv3_block = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv4_block = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv5_block = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 11 * 20, 1024)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(1024, 54)  # Assuming 54 classes for Uno cards\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1_block(x)\n",
    "        x = self.conv2_block(x)\n",
    "        x = self.conv3_block(x)\n",
    "        x = self.conv4_block(x)\n",
    "        x = self.conv5_block(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvolutionalNeuralNetwork()\n",
    "model.to(device)\n",
    "model = torch.compile(model, backend=\"inductor\")\n",
    "swa_model = AveragedModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(64, IMG_CHANNELS, IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Optimising model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Learning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "REG_FACTOR = 5e-3\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Optimizer & cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=REG_FACTOR, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swa_scheduler = SWALR(optimizer, swa_lr=1e-3)\n",
    "# Start SWA after 10 epochs\n",
    "swa_start = 10  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "\n",
    "    training_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)  # Move data to device\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item() * X.size(0)\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss_item = loss.item()\n",
    "            current = batch * len(X)\n",
    "            print(f\"loss: {loss_item:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    avg_loss = training_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Define test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)  # Move data to device\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            test_loss += loss.item() * X.size(0)\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    avg_loss = test_loss / total\n",
    "    accuracy = correct / total\n",
    "    print(f\"Avg loss: {avg_loss:>8f}, Accuracy: {(100*accuracy):>0.1f}%\\n\")\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Define overfitting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overfitting(train_loss, val_loss, train_acc, val_acc, threshold=0.1):\n",
    "    loss_gap = abs(train_loss - val_loss)\n",
    "    acc_gap = abs(train_acc - val_acc)\n",
    "    \n",
    "    is_overfitting = (loss_gap > threshold) and (train_acc > val_acc + threshold)\n",
    "    \n",
    "    if is_overfitting:\n",
    "        print(f\"Warning: Possible overfitting detected\")\n",
    "        print(f\"Loss gap: {loss_gap:.4f}, Accuracy gap: {acc_gap:.4f}\")\n",
    "    \n",
    "    return is_overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "epoch_times = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_metrics = None\n",
    "stopped_early = False\n",
    "is_overfitting = 0\n",
    "patience = 10  # Number of epochs with no improvement after which training will be stopped\n",
    "total_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    train_loss, train_accuracy = train_loop(train_loader, model, loss_fn, optimizer)\n",
    "\n",
    "    # Update SWA after swa_start epochs\n",
    "    if epoch >= swa_start:\n",
    "        swa_model.update_parameters(model)\n",
    "        swa_scheduler.step()\n",
    "    else:\n",
    "        scheduler.step(train_loss)  # Use regular scheduler before SWA\n",
    "        \n",
    "    val_loss, val_accuracy = test_loop(val_loader, model, loss_fn)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    epoch_times.append(epoch_time)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} completed in {epoch_time:.2f} seconds\")\n",
    "    print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\\n\")\n",
    "\n",
    "    # Increment overfitting counter if overfitting detected\n",
    "    if check_overfitting(train_loss, val_loss, train_accuracy, val_accuracy):\n",
    "        is_overfitting += 1\n",
    "    else:\n",
    "        is_overfitting = 0\n",
    "\n",
    "    # Check all conditions\n",
    "    accuracy_gap = abs(train_accuracy - val_accuracy)\n",
    "    conditions_met = (\n",
    "        train_loss > 0.13 and\n",
    "        val_loss > 0.13 and\n",
    "        train_accuracy < 0.99 and\n",
    "        val_accuracy < 0.99 and\n",
    "        accuracy_gap < 0.03\n",
    "    )\n",
    "\n",
    "    # Save model if conditions are met and validation loss improved\n",
    "    if conditions_met and val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_metrics = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'val_accuracy': val_accuracy\n",
    "        }\n",
    "        torch.save(model.state_dict(), '../data/models/best_model.pth')\n",
    "\n",
    "    # Stop if overfitting persists for multiple epochs\n",
    "    if is_overfitting >= patience:\n",
    "        print(f\"Early stopping triggered due to persistent overfitting.\")\n",
    "        stopped_early = True\n",
    "        break\n",
    "\n",
    "update_bn(train_loader, swa_model, device=device)\n",
    "\n",
    "total_training_time = time.time() - total_start_time\n",
    "\n",
    "# Save both models\n",
    "torch.save(model, '../data/models/final_model.pth')\n",
    "torch.save(swa_model, '../data/models/final_swa_model.pth')\n",
    "\n",
    "if best_model_metrics:\n",
    "    print(\"\\nBest model saved with metrics:\")\n",
    "    for key, value in best_model_metrics.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nTraining complete in {total_training_time:.2f} seconds\")\n",
    "print(\"\\n-------------------------------\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Plot model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(1, len(train_losses) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_losses, label='Training Loss')\n",
    "plt.plot(epochs_range, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Accuracy graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. Epoch duration graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, epoch_times, label='Time per Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Time Taken per Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. Create & load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvolutionalNeuralNetwork()\n",
    "model.to(device)\n",
    "model = torch.compile(model, backend=\"inductor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopped_early = False\n",
    "\n",
    "# Load the best model (if saved during early stopping)\n",
    "if stopped_early:\n",
    "    model.load_state_dict(torch.load('../data/models/best_model.pth'))\n",
    "else:\n",
    "    model = torch.load('../data/models/full_model_v1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Test model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "print(\"Test Results on the Test Set:\")\n",
    "test_loop(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3. Test model on own image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = v2.Compose([\n",
    "    v2.Resize((360, 640)),\n",
    "    v2.RandomAdjustSharpness(sharpness_factor=1.1, p=1.0),  # Subtle sharpness changes\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=mean, std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the image\n",
    "image_path = 'Yellow_Draw_2.jpg' \n",
    "image = Image.open(image_path).convert('RGB')\n",
    "input_tensor = image_transform(image)\n",
    "input_tensor = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "input_tensor = input_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    predicted_class = output.argmax(dim=1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names\n",
    "class_names = full_dataset.classes\n",
    "predicted_label = class_names[predicted_class]\n",
    "print(f\"Predicted class: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
