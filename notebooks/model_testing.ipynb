{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('../data/raw', batch_size=16, image_size=(256, 256), color_mode='rgb', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: (x / 255.0, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_iterator = data.as_numpy_iterator()\n",
    "batch = scaled_iterator.next()\n",
    "batch[0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*0.75)\n",
    "val_size = int(len(data)*0.17)\n",
    "test_size = int(len(data)*0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.take(train_size)\n",
    "val_data = data.skip(train_size).take(val_size)\n",
    "test_data = data.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Build Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much smaller L2 regularization\n",
    "reg_factor = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # First Convolutional Block - reduced initial filters\n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(256, 256, 3),\n",
    "            kernel_regularizer=l2(reg_factor)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(reg_factor)),\n",
    "        BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu',\n",
    "            kernel_regularizer=l2(reg_factor)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu',\n",
    "            kernel_regularizer=l2(reg_factor)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Third Convolutional Block\n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu',\n",
    "            kernel_regularizer=l2(reg_factor)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu',\n",
    "            kernel_regularizer=l2(reg_factor)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Fourth Convolutional Block\n",
    "    Conv2D(256, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(reg_factor)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Flatten the output and add dense layers\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(reg_factor)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),  # Slightly reduced dropout for longer training\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(reg_factor)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(24, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = r'../data/logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced training configuration for longer training\n",
    "training_config = {\n",
    "    'epochs': 20,  # Increased epochs\n",
    "    'batch_size': 16,\n",
    "    'callbacks': [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,  # Increased patience\n",
    "            restore_best_weights=True,\n",
    "            min_delta=0.0001  # Smaller improvement threshold\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=8,  # Increased patience\n",
    "            min_lr=1e-7,  # Lower minimum learning rate\n",
    "            min_delta=0.0001\n",
    "        ),\n",
    "        tensorboard_callback\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for better generalization during longer training\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomBrightness(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_data = train_data.map(lambda x, y: (data_augmentation(x,training=True), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    augmented_train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=training_config['epochs'],\n",
    "    batch_size=training_config['batch_size'],\n",
    "    callbacks=training_config['callbacks']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_data.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pre.result(), re.result(), acc.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ( yhat >= 0) and ( yhat <= 1):\n",
    "    print('Card is 7 blue')\n",
    "else:\n",
    "    print('Card is not 7 blue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
